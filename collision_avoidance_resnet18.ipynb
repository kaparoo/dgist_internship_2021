{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "educational-scope",
   "metadata": {},
   "source": [
    "# Collision Avoidance (ResNet18)\n",
    "\n",
    "Reference: [NVIDIA JetBot Github Repository][JETBOT_GITHUB_LINK]\n",
    "\n",
    "[JETBOT_GITHUB_LINK]: https://github.com/NVIDIA-AI-IOT/jetbot/tree/master/notebooks/collision_avoidance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-protection",
   "metadata": {},
   "source": [
    "## 0. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim # for SGD\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models # for resnet18\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-strand",
   "metadata": {},
   "source": [
    "## 1. Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./datasets/dataset_white\"\n",
    "# DATASET_PATH = \"./datasets/dataset_black\"\n",
    "\n",
    "IMAGE_WIDTH  = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "\n",
    "# The two constants below use the values specified in the reference.\n",
    "NORMALIZE_MEAN = (0.485, 0.456, 0.406)\n",
    "NORMALIZE_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "total_dataset = ImageFolder(\n",
    "    DATASET_PATH,\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
    "    ])\n",
    ")\n",
    "\n",
    "print(f\"{len(total_dataset)} images have been loaded.\") # Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RATIO = (0.8, 0.1, 0.1) # train : valid : test\n",
    "\n",
    "total_data_num = len(total_dataset)\n",
    "\n",
    "train_data_num = int(total_data_num * SPLIT_RATIO[0])\n",
    "valid_data_num = int(total_data_num * SPLIT_RATIO[1])\n",
    "model_data_num = train_data_num + valid_data_num\n",
    "\n",
    "test_data_num  = int(total_data_num * SPLIT_RATIO[2])\n",
    "\n",
    "model_dataset, test_dataset  = random_split(total_dataset, (model_data_num, test_data_num))\n",
    "train_dataset, valid_dataset = random_split(model_dataset, (train_data_num, valid_data_num))\n",
    "\n",
    "#-- Logger --#\n",
    "print(f\"Train Dataset: {len(train_dataset)} images.\") # print(train_data_num)\n",
    "print(f\"Validation Dataset: {len(valid_dataset)} images.\") # print(valid_data_num)\n",
    "print(f\"Test Dataset: {len(test_dataset)} images.\") # print(test_data_num)\n",
    "#-- Logger --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-elimination",
   "metadata": {},
   "source": [
    "## 2. Define the model (ResNet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 2) # 2 for 'blocked' and 'free'\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"This environment supports the CUDA.\") # Logger\n",
    "else:\n",
    "    print(\"This environment does not support the CUDA.\") # Logger\n",
    "    print(\"The model will run on the CPU instead.\") # Logger\n",
    "    # pass\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# print(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-remains",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_TIME = time.strftime('%Y%m%d_%I%M%S%p', time.localtime())\n",
    "BEST_MODEL_PATH = f\"./best_models/best_model_resnet18_{CURRENT_TIME}.pth\"\n",
    "\n",
    "# hyper parameters\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.9\n",
    "L2_CONST = 1e-5\n",
    "\n",
    "best_accuracy = 0.0 # validation accuracy\n",
    "\n",
    "# SGD optimizer with L2 regularization\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                      lr=LEARNING_RATE,\n",
    "                      momentum=MOMENTUM,\n",
    "                      weight_decay=L2_CONST)\n",
    "\n",
    "accuracy_history = []\n",
    "\n",
    "\n",
    "# model training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    valid_error = 0.0\n",
    "    for images, labels in iter(valid_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        outputs = outputs.argmax(1)\n",
    "        valid_error += float(torch.sum(torch.abs(labels - outputs)))\n",
    "        \n",
    "    valid_accuracy = 1.0 - (valid_error / valid_data_num)\n",
    "    accuracy_history.append(valid_accuracy)\n",
    "    \n",
    "    print(f\"[Epoch {epoch}] Validation accuracy: {valid_accuracy: .5f}\") # Logger\n",
    "    \n",
    "    if valid_accuracy > best_accuracy:\n",
    "        print(\"\\tSave the best model.\") # Logger\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Training Complete!\") # Logger\n",
    "print(f\"Best validation accuracy: {best_accuracy}\") # Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PATH = f\"./plots/validation_accuracy_plot_restnet18_{CURRENT_TIME}.png\"\n",
    "\n",
    "title = \"Validation Accuracy Plot (ResNet18)\"\n",
    "subtitle = f\"(lr={LEARNING_RATE}, momentum={MOMENTUM})\"\n",
    "\n",
    "plt.plot(accuracy_history)\n",
    "plt.suptitle(title)\n",
    "plt.title(subtitle)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation accuracy\")\n",
    "\n",
    "plt.savefig(PLOT_PATH)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-andrews",
   "metadata": {},
   "source": [
    "## 4. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "\n",
    "print(f\"Load model from \\\"{BEST_MODEL_PATH}\\\".\") # Logger\n",
    "\n",
    "model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
    "\n",
    "model = model.to(device)\n",
    "model = model.eval().half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_case_count = 0\n",
    "\n",
    "for case, sample in enumerate(iter(test_loader)):\n",
    "    image, label = sample\n",
    "    image = image.to(device).half()\n",
    "    label = int(label)\n",
    "    predict = model(image)\n",
    "    predict = F.softmax(predict, dim=1)\n",
    "    predict = predict.data[0]\n",
    "    \n",
    "    #-- Logger --#\n",
    "    print(f\"[Test Case {case}]\")\n",
    "    print(f\"\\t[Prediction] {float(predict[0]) : .5f} : {float(predict[1]) : .5f}\")\n",
    "    print(f\"\\t[Real output] {label}\")\n",
    "    \n",
    "    if label == 1 and float(predict[0]) < float(predict[1]):\n",
    "        correct_case_count += 1\n",
    "        print(f\"\\t[Result] Correct\")\n",
    "    elif label == 0 and float(predict[0]) > float(predict[1]):\n",
    "        correct_case_count += 1\n",
    "        print(f\"\\t[Result] Correct\")\n",
    "    else:\n",
    "        print(f\"\\t[Result] Incorrect\")\n",
    "    #-- Logger --#\n",
    "    \n",
    "print(f\"[Total Test Accuracy] {correct_case_count/test_data_num : .5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
