{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "czech-zambia",
   "metadata": {},
   "source": [
    "# Collision Avoidance (DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-massage",
   "metadata": {},
   "source": [
    "## 0. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim # for SGD\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import os # isdir, mkdir\n",
    "import matplotlib.pyplot as plt\n",
    "from time import localtime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-might",
   "metadata": {},
   "source": [
    "## 1. Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_PATH = \"./datasets/dataset_white\"\n",
    "DATASET_PATH = \"./datasets/dataset_blue\"\n",
    "\n",
    "IMAGE_WIDTH  = 32\n",
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_CHANNEL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset = ImageFolder(\n",
    "    DATASET_PATH,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
    "        transforms.Grayscale(num_output_channels=IMAGE_CHANNEL),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.449], [0.226]),\n",
    "        transforms.Lambda(lambda img: torch.flatten(img)) # https://stackoverflow.com/questions/60900406/\n",
    "    ])\n",
    ")\n",
    "\n",
    "print(f\"{len(total_dataset)} images have been loaded.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RATIO = (0.8, 0.1, 0.1) # train : valid : test\n",
    "\n",
    "total_data_num = len(total_dataset)\n",
    "\n",
    "train_data_num = int(total_data_num * SPLIT_RATIO[0])\n",
    "valid_data_num = int(total_data_num * SPLIT_RATIO[1])\n",
    "model_data_num = train_data_num + valid_data_num\n",
    "\n",
    "test_data_num  = int(total_data_num * SPLIT_RATIO[2])\n",
    "\n",
    "model_dataset, test_dataset  = random_split(total_dataset, [model_data_num, test_data_num])\n",
    "train_dataset, valid_dataset = random_split(model_dataset, [train_data_num, valid_data_num])\n",
    "\n",
    "#-- Logger --#\n",
    "print(f\"Train Dataset: {len(train_dataset)} images.\") # print(train_data_num)\n",
    "print(f\"Validation Dataset: {len(valid_dataset)} images.\") # print(valid_data_num)\n",
    "print(f\"Test Dataset: {len(test_dataset)} images.\") # print(test_data_num)\n",
    "#-- Logger --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-punishment",
   "metadata": {},
   "source": [
    "## 2. Define the model (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = IMAGE_HEIGHT * IMAGE_WIDTH * IMAGE_CHANNEL\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    \n",
    "    \"\"\"Custom DNN model for the Image classification.\"\"\"\n",
    "    \n",
    "    __slots__ = \"__model\"\n",
    "    \n",
    "    def __init__(self, input_dim=INPUT_SIZE, output_dim=2, hidden_dims=(128, 64, 32), do_batch_normal=True, dropout=0):\n",
    "        \n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        dims_list = (input_dim, *hidden_dims)\n",
    "        model_components = []\n",
    "        \n",
    "        # hidden layers\n",
    "        for i in range(1, len(dims_list)):\n",
    "            current_input_dim = dims_list[i-1]\n",
    "            current_output_dim = dims_list[i]\n",
    "            model_components.append(nn.Linear(current_input_dim, current_output_dim))\n",
    "            \n",
    "            if do_batch_normal == True:\n",
    "                model_components.append(nn.BatchNorm1d(current_output_dim))\n",
    "            \n",
    "            model_components.append(nn.ReLU())\n",
    "            \n",
    "            if dropout > 0:\n",
    "                model_components.append(nn.Dropout(dropout))\n",
    "        \n",
    "        # output layer\n",
    "        output_layer = nn.Linear(dims_list[-1], output_dim)\n",
    "        model_components.append(output_layer)\n",
    "        model_components.append(nn.Softmax(dim=1))\n",
    "        \n",
    "        # make DNN model\n",
    "        self.__model = nn.Sequential(*model_components)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.__model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-pointer",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN(hidden_dims=(128, 64, 32))\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"This environment supports the CUDA.\") # Logger\n",
    "else:\n",
    "    print(\"This environment does not support the CUDA.\") # Logger\n",
    "    print(\"The model will be running on the CPU instead.\") # Logger\n",
    "    # pass\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# print(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"./best_models\"):\n",
    "    os.mkdir(\"./best_models\")\n",
    "\n",
    "CURRENT_TIME = strftime('%Y%m%d_%H%M%S', localtime())\n",
    "BEST_MODEL_PATH = f\"./best_models/best_model_dnn_{CURRENT_TIME}.pth\"\n",
    "\n",
    "# hyper parameters\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.9\n",
    "L2_CONST = 1e-4\n",
    "\n",
    "best_accuracy = 0.0 # validation accuracy\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD optimizer with L2 regularization\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                      lr=LEARNING_RATE,\n",
    "                      momentum=MOMENTUM,\n",
    "                      weight_decay=L2_CONST)\n",
    "\n",
    "accuracy_history = []\n",
    "\n",
    "EPOCH_DIGIT = len(str(EPOCHS)) # for Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-whole",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    valid_error = 0.0\n",
    "    for images, labels in iter(valid_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        valid_error += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n",
    "        \n",
    "    valid_accuracy = 1.0 - float(valid_error) / float(valid_data_num)\n",
    "    \n",
    "    if valid_accuracy < 0:\n",
    "        valid_accuracy = 0\n",
    "    \n",
    "    accuracy_history.append(valid_accuracy)\n",
    "    \n",
    "    print(f\"[Epoch {epoch: >{EPOCH_DIGIT}d}] Accuracy: {valid_accuracy: .5f}\") # Logger\n",
    "    \n",
    "    if valid_accuracy > best_accuracy:\n",
    "        print(\"\\tSave the best model\") # Logger\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Training Complete!\") # Logger\n",
    "print(f\"Best validation accuracy: {best_accuracy: .5f}\") # Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"./plots\"):\n",
    "    os.mkdir(\"./plots\")\n",
    "\n",
    "PLOT_PATH = f\"./plots/validation_accuracy_plot_dnn_{CURRENT_TIME}.png\"\n",
    "\n",
    "title = \"Validation Accuracy Plot (DNN)\"\n",
    "subtitle = f\"(lr={LEARNING_RATE}, momentum={MOMENTUM} l2_constant={L2_CONST})\"\n",
    "\n",
    "plt.plot(accuracy_history)\n",
    "plt.suptitle(title)\n",
    "plt.title(subtitle)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation accuracy\")\n",
    "\n",
    "plt.savefig(PLOT_PATH)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-update",
   "metadata": {},
   "source": [
    "## 4. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-ecuador",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correct_case_count = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for case, sample in enumerate(iter(test_loader)):\n",
    "    image, label = sample\n",
    "    image = image.to(device)\n",
    "    label = int(label)\n",
    "    predict = model(image)\n",
    "    predict = predict.flatten()\n",
    "    \n",
    "    #-- Logger --#\n",
    "    print(f\"[Test Case {case}]\")\n",
    "    print(f\"\\t[Prediction] {float(predict[0]): .5f} : {float(predict[1]): .5f}\")\n",
    "    # print(f\"\\t[Prediction] Blocked : Free\")\n",
    "    print(f\"\\t[Real output] {label}\") # 0: Blocked, 1: Free\n",
    "    #-- Logger --#\n",
    "    \n",
    "    if label == 1 and float(predict[0]) < float(predict[1]):\n",
    "        correct_case_count += 1\n",
    "        print(f\"\\t[Result] Correct\") # Logger\n",
    "    elif label == 0 and float(predict[0]) > float(predict[1]):\n",
    "        correct_case_count += 1\n",
    "        print(f\"\\t[Result] Correct\") # Logger\n",
    "    else:\n",
    "        print(f\"\\t[Result] Incorrect\") # Logger\n",
    "        # pass\n",
    "    \n",
    "print(f\"[Total Test Accuracy] {correct_case_count/test_data_num : .5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
